<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Real-Time Voice Assistant</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <style>
    body {
      font-family: system-ui, -apple-system, sans-serif;
      background: #0b1220;
      color: #e5e7eb;
      padding: 24px;
    }
    h1 { margin-bottom: 12px; }
    .controls { margin-bottom: 12px; }
    button, select {
      padding: 8px 12px;
      font-size: 14px;
      margin-right: 8px;
    }
    pre {
      background: #020617;
      padding: 12px;
      min-height: 80px;
      white-space: pre-wrap;
    }
    #status { margin-top: 8px; opacity: 0.85; }
  </style>
</head>

<body>
  <h1>ðŸŽ§ Voice Assistant</h1>

  <div class="controls">
    <select id="language">
      <option value="en-US">English (US)</option>
      <option value="en-IN">English (India)</option>
    </select>
    <button id="startBtn">Start</button>
    <button id="stopBtn" disabled>Stop</button>
  </div>

  <div id="status">Idle</div>
  <pre id="transcript"></pre>

<script type="module">
/* ============================================================
   CONFIG â€” MUST MATCH BACKEND
============================================================ */
const CLIENT_ID = "user_" + Math.random().toString(36).substring(2, 10);

const WS_URL =
  (location.protocol === "https:" ? "wss://" : "ws://") +
  location.host +
  "/ws/voice?client_id=" + CLIENT_ID;

/* ============================================================
   WebRTC Setup
============================================================ */
let ws, pc, audioElement;

const startBtn = document.getElementById("startBtn");
const stopBtn = document.getElementById("stopBtn");
const statusEl = document.getElementById("status");
const transcriptEl = document.getElementById("transcript");
const languageSel = document.getElementById("language");

startBtn.onclick = start;
stopBtn.onclick = stop;

async function start() {
  // WebSocket for signaling and control only
  ws = new WebSocket(WS_URL);
  
  ws.onopen = async () => {
    statusEl.textContent = "Connecting audio...";
    await setupWebRTC();
  };
  
  ws.onmessage = handleSignaling;
  ws.onclose = cleanup;
  
  startBtn.disabled = true;
  stopBtn.disabled = false;
}

async function setupWebRTC() {
  // Create RTCPeerConnection
  pc = new RTCPeerConnection({
    iceServers: [
      { urls: "stun:stun.l.google.com:19302" },
      { urls: "stun:stun1.l.google.com:19302" }
    ]
  });
  
  // Get microphone with optimal settings
  const stream = await navigator.mediaDevices.getUserMedia({
    audio: {
      channelCount: 1,
      sampleRate: 48000,
      echoCancellation: true,
      noiseSuppression: true,
      autoGainControl: true
    }
  });
  
  // Add local audio track to peer connection
  stream.getTracks().forEach(track => {
    pc.addTrack(track, stream);
  });
  
  // Handle incoming audio (bot speaking)
  pc.ontrack = (event) => {
    if (!audioElement) {
      audioElement = document.createElement("audio");
      audioElement.autoplay = true;
      document.body.appendChild(audioElement);
    }
    audioElement.srcObject = event.streams[0];
    statusEl.textContent = "Listening...";
  };
  
  // Handle ICE candidates
  pc.onicecandidate = (event) => {
    if (event.candidate) {
      ws.send(JSON.stringify({
        type: "ice_candidate",
        candidate: event.candidate.toJSON()
      }));
    }
  };
  
  // Create and send offer
  const offer = await pc.createOffer({
    offerToReceiveAudio: true
  });
  await pc.setLocalDescription(offer);
  
  ws.send(JSON.stringify({
    type: "webrtc_offer",
    sdp: offer.sdp,
    language: languageSel.value
  }));
}

async function handleSignaling(event) {
  const msg = JSON.parse(event.data);
  
  switch (msg.type) {
    case "webrtc_answer":
      await pc.setRemoteDescription({
        type: "answer",
        sdp: msg.sdp
      });
      statusEl.textContent = "Connected - Listening...";
      break;
      
    case "ice_candidate":
      if (msg.candidate) {
        await pc.addIceCandidate(new RTCIceCandidate(msg.candidate));
      }
      break;
      
    case "transcript":
      transcriptEl.textContent = msg.text;
      break;
      
    case "ready":
      statusEl.textContent = "Ready";
      break;
      
    case "error":
      statusEl.textContent = "Error: " + msg.error;
      console.error("Server error:", msg.error);
      break;
  }
}

function stop() {
  ws?.send(JSON.stringify({ type: "stop" }));
  cleanup();
}

function cleanup() {
  if (pc) {
    pc.close();
    pc = null;
  }
  if (audioElement) {
    audioElement.srcObject = null;
  }
  if (ws) {
    ws.close();
    ws = null;
  }
  
  startBtn.disabled = false;
  stopBtn.disabled = true;
  statusEl.textContent = "Idle";
}
</script>
</body>
</html>
